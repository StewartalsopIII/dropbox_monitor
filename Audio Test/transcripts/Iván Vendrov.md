# Transcript

**Generated**: 2025-01-24 18:06:29

**File**: IvaÃÅn Vendrov.m4a

**Size**: 89.21 MB

**Processed**: 2025-01-24 18:06:29

beep

Welcome to the Crazy Wisdom Podcast. My guest today is Ivan Vendrov and uh this is actually our second interview and we just had a wonderful talk yesterday yesterday in Buenos Aires and now we're in a park, looking at some swans uh crossing the road, and we're about to go through a walk and do an interview. So, welcome to the show, Ivan.

Thanks, Stuart. Great to be back.

Uh so what would you say is the most interesting thing you've learned about AI in the last week? In the last week, uh ooh.

I'm not sure I learned anything new in the last week. I feel like I've developed more confidence in some old ideas. Not not my ideas, other people's ideas. Which one is the most The honestly, the the oldest and most important one, still under underappreciated after 10 years is the bitter lesson.  Yes. Um, right? Rich Sutton, the uh, legendary reinforcement learning researcher from University of Alberta uh, wrote this essay a long time ago called The Bitter Lesson, which is like the main lesson of AI research for the last 70 years is that general methods that leverage uh, tons of compute and tons of data win out over everything else. So, stop trying to impose your human concepts Oh man. onto the system. Yeah. Just let the information flow, let the compute flow. Uh, that wins in the end. Um, and Ilya Sutskever famously articulated this as like, if you make the network big enough, and I, one of his NeurIPS presentations, if you make the network big enough, and if you train on enough data, success is guaranteed. Wow. Um, and that sounded crazy back in like 2014, 2015 when he first said it. And now uh, actually, I think most people still haven't integrated that into their lesson, but but everybody is saying in the last few weeks that that's lesson is slowing down. Or that lesson is not applicable to today. Is that right?

Yeah. I think they're saying something, I think, usually when people say this, they're pointing to the fact that we had uh, like the difference between, let's say, GPT2, GPT3, GPT4 is the difference between a demo and something that could transform the economy on its own account. And we haven't really seen much in the last year since GPT4 was released, since Chat GPT was released, um, that would, you know, follow that exponential trajectory. Um, I think there is a case to be made that language modeling, in particular, has slowed down. But I think that still follows the bitter lesson. It's just like, yeah, we we ran out of language data, in some fundamental sense. High-quality language data. Yeah, interesting. Yeah, yeah, yeah. So it's more the aspect not of the computation but the data inputted into the computation. Data, and yet, I mean, both. Um, both, both are bottlenecks. Um, like we actually don't have that many GPUs. Like what percentage of the world economy is dedicated towards building GPUs? What percentage of world energy? It's still less than 1%. Um, so we have quite a bit, yeah, we have a lot of scaling left to go. We We haven't really used image and video data fully yet. Okay. And what about the infrastructure, like and what I mean infrastructure probably, it's like autonomous. 

things as well, autonomous agents, but also just like getting the data in there. Yeah. Yeah. I imagine the problem that I have and what a lot of other people have is getting the data in there. That's the biggest challenge. And I'll go through one of the solutions that I've done recently, which is I do my spaced repetition. Yeah. Now I'm putting the transcripts of books or videos in that spaced repetition. Yes. So I can then ask questions about it with the LLM. Right. Um, but that infrastructure, that wh- uh what do you think about that? 'Cause that feels like a longer term thing, right? I could give another example about Apple, Apple Intelligence. Sure. Apple Intelligence did not implement AI well. Right. It's not a good implementation, and it feels like Yeah. they don't know how to do it. We like, startups don't know how to do it. Yeah. Nobody knows how to do it. What do you think? Yeah.

That seems right. I feel like we don't yet have, I mean, in some sense, like, ChatGPT was no, was not different from, uh, like the GPT APIs that had existed previously. It's just that it was packaged in a nice interface. And with some, like, RL fine tuning. But fundamentally, the intelligence had been available for about a year beforehand. It's just that they packaged it in a nice interface. Um, and so, yeah, I think like, there's a huge, uh, what I would call it, UX overhang, where there's like so much raw intelligence in these systems, even in GPT-4 class systems, let alone the stuff that's coming out now and going to be coming out in a year. Um, and it it's just like, really hard to integrate it in with the economy. An example I would give is actually like, the dot-com bubble. Right? It's like, in 1999, 1998, I wasn't really around then, but my understanding of that period is like, people got super excited about the internet, the potential of the internet. Everything is connected now. We don't need centralized actors. Like, there's like thousands of times more information bandwidth available to people in, in terms of like, communicating. We can totally change markets. We can totally change society. But it took 10 years. But it took 10 years, because the economy takes a while to adjust. People, like, people are conservative. It takes a lot of time to learn to trust a new system, and it's just like, things diffuse slowly. Um, and do you think that, because we now have something different from when that happened, which is that the public is now

very much

involved in technology. Mm. And so there might not be that same skepticism Right. on the user's part. Yeah. But that's only one part of the equation because there's also a bud- a bunch of other parts which is just like the data problem Sure. What are some of the other ones?

Yeah, the data problem I I actually don't know how to characterize this very well. But it's something almost at the level of I want to say it's almost at the level of like musculature, right? Like how are you used to using Yeah. Yeah. Yeah, interesting. like if if you look at an old person trying to use an iPad, like they even they can't they often can't even they don't even know how to click. Yes. Right? Like the tapping is uncomfortable or like unintuitive. And I think it's similar, it's just like it takes a while for humans to learn how to in their like muscle memory at like the fun- like integrate technology into kind of the core of how they approach their work and how they do their work, how they think. Yeah. Yeah. So that takes a long time. That being said, I'm not predicting it'll take 15 years. Like with the .com boom, I think the internet has paved the way for this technology to diffuse much quicker. Yeah. Yeah, interesting. Think of like ChatGPT getting to what whatever it was, like 2 million users within a week or a couple weeks. That would not have happened prior prior to the internet. Yes. Yes. And do you think it's stalled still? It stalled at the 200 million uh or like because that's what I'll give a a anecdote from AI whispers is that what a year ago, it was really it we started off with a big boom. Everybody's really interested in it. Yeah. Yeah. Then within four months, it could have been because most foreigners who are interested in it left because it became winter here. But it could also be that that it that a lot of people got excited about it Yeah. and a lot of people were like, I have no idea what the hell this is. Like what what what do I even do with this thing? And then like some core group of people Yeah. keep on using it.

And and it gets into questions about knowledge and what knowledge is and what information is. Right. Uh

That's feels like the hardest thing for me to wrap my head around is what does this represent in terms of of knowledge and information, the chatbot. The chatbot's the main way that I use it still. Right. Are you using the APIs to do things?

that you wouldn't do with the chatbot. Um, P

Definitely using the APIs for, uh, so yeah, what are APIs useful useful for that you can't use the chatbot for? If I want like 10 different generations on a particular creative idea or something, or I want like I'm writing an essay and it's like here's 10 different things I could, here's 10 different ways I would branch from it. That's something where it's nice to use the API and just call it 10 times. Um, especially if you're using a database model, or yeah. Or you have a dedicated. Yeah, a dedicated use case. Yeah. that you want to query against over and over again. Yeah.

Um but I mean, the chatbots, I'm I'm actually surprised by just how powerful the chatbot Facebook is. The chatbot in your face is which Facebook predicted. Facebook, the one where like 10 years ago they they opened it up to chatbots basically inside of Facebook Messenger. Yeah. And I bet Zuckerberg is like, "Aha! Told ya!" Yeah. Actually, he might not be that type of character. Do you think he's a "I told you so" character? We don't have to talk about him either. Um I honestly, I feel like with people like that you never know who they really are, so I can't tell. Yeah. Yeah. He's got a great PR team. That's all I got. Yeah. He does. He does have a great PR team. Uh and um but that gets me to the question we were talking about yesterday. How do you evaluate high intelligence? Right. Like how do you evaluate, not only high intelligence, Yeah. also divergent intelligence. A type of intelligence, and that is I mean, is that intelligence? Like when an intelligence is highly divergent, Right. it thinks out, it doesn't mean mean better or worse, it means like focused on areas that you're not focused on, right? Yeah.

Uh that's a cool that's a cool definition. I think that's I think that's one reason I would frame Yeah, I would say like all intelligence is collective intelligence. Yeah, interesting. Um, for something it's just like when people use the word intelligence like, "Oh, I need to be smarter" or "I need like better ideas. I need to hire someone who's smarter after that near me". What they really mean is like, "I want to hire the kind of person who sees the patterns that I don't see." Yes, interesting. And so it's about complementarity. Yeah. uh, rather than about like some uniform scale of intelligence. Yeah. That kind of gets into the problem of Western civilization in terms of the individual, right? Because it doesn't accurately represent that we are social by nature, and our intelligence is social, and there's no way you can get around that. I think the individual part is important. I think that, like, I'm not denying that. I think it's really important for a certain uh stage of maturity, Yeah. but I think beyond that maturity then it makes sense to be realized it was all interdependent. Yeah. Interdependent to a degree that is like insane. Yeah. I think this is um I was at a um uh kind of like future of democracy conference last week in DC, and they were talking about kind of big tech companies, the tech oligarchs, how they've like taken over the centers of power, bottlenecked, bottlenecked everything, and I I believe that, but I think there's a kind of like misdiagnosis that comes from I want to say Marxism or something, of like, "Oh yeah, it's all about these like commanding heights of the economy." The way the tech oligarchs got so powerful is not by like hacking DC or New the DC or New York centers of power, it's by hacking the human minds. It turns out that the human mind is like way more divided Yeah. than anyone thought, and that, like, yeah, you can actually just like mine people for attention and for money very quick very very easily by just, like, uh getting sort of like getting underneath whatever we call the ego is like that control structure that organizes and coordinates all the different parts of you, quote-unquote you, atomic and individual steward. Yeah. Yeah, yeah, yeah, yeah. Uh and tech companies just like got underneath that oodaloop and disaggregated the ego, and now they can like, you know, whenever you're late, whenever you're feeling like tired or upset, or like you need some emotional soothing, you turn to your Twitter feed or you turn to TikTok, and you scroll, and so they're mining you. You don't endorse doing that scrolling, but no one asked you. Yeah. I mean, in terms of conditions, could be said where it is, but where are those terms of conditions? Does it say that they're doing that? Maybe it does. Maybe with LLMs, we can now disambiguate those terms of service and understand what we're signing up for. That's the hope, is that like yeah, I think I am I'm less and less a like a liberal individualist uh uh maybe as I age, I feel like there's a common thing that happens as people get older. But if I were, I'd be like, "Okay, well the ego is under attack, it's basically broken now." Like no one actually has atomic egos. Very few people are doing like the Newton Leonardo da Vinci thing of like, "I will" um oh, there's a really interesting concept. I forget who articulated this. It's something about the condition the condition of modernity or The Great Endarkenment, I think is the book. It's the the condition of modernity is hyperspecialization. Yeah, yeah. And every problem in modernity has to cover so many different fields of expertise that no individual can actually understand what's happening to them or what to do about it, and so you have to like trust experts. I think what the original Enlightenment was the precise opposite of this. It was a movement for intellectual autonomy. Yeah. Stop reading Aristotle, right? Stop reading the Stop reading the Pope. Look at the world, and like decide what you want to do. That was like the So I mean if so I think that if I was a so we're at late-stage Enlightenment. Yeah, late-stage Enlightenment or Endarkenment or whatever whatever it's called. And we're moving towards something new that accurately places the individual within the collective. I don't think it gets rid of the individual. No. No. I mean, the individual is the individual has to exist purely because of like the physics of information bandwidth or something. It's just like the lobes, the two lobes of your brain are connected with like a roughly 1 GB/s cable, and you and I talking right now are connected with at most 40 bits/s, and we're not even making good use of that. So, it's like your the the parts of you are much like it's it's much more natural for you to be a political unit than for us two to be a political unit. Yeah. Time. Time piece, but that gets into direct brain-computer interface, not even direct brain-computer interface, passive brain-computer interface, as well, which is what everyone's working on. Facebook's working on it. Uh I believe I I asked my friend who had the the glasses whether it came with a watch, because somebody told me the watch uh registers neural signals. Um but she said it didn't come with a watch, so there's another part about uh the world that we live in in terms of mis misinformation and facts, and trying to accurately fact-check things that are going on. The LLM has been a boon for that, uh and because now I can go fact-check, but now I'm depending on whoever's training the LLM Right. in order for that specific question, if they if it if they've already flagged it, then they already do RLHF, uh and and that will then determine the responses. Is that accurate? Yeah. Yeah, basically accurate. Yeah. I mean, that's why uh, "Who is the stability CEO?" Right? "Not your weights, not your brain." Yes, yeah, yeah, yeah. I think long term, that is, yeah, I think there is a um some- someone asked me at the conference actually like what I would recommend to citizens, you know, who want to maintain the future of democr- who want to, like, maintain something like democracy into the future, Yeah. and I think it has to do with, yeah, like encryption, open source, like that movement is actually our best hope for that, Yup. like the thing that will uh like I don't quite know how this will work, like I'm not sure.

local computing, like locally running language models, is the future. Because like there's too many returns to scale. But like you can get most of that security by running language models in like Amazon's virtual private cloud. Um, but that's like what governments do, like the government of Singapore runs it, and I don't know that they're sure that the CIA isn't watching their prompts. But like, I think they're pretty sure, or at least it's like it would be hard enough, but yeah. This goes back to the Apple thing. I was just talking with my friend about Apple. Apple's whole thing is that they don't let the government in. They don't let the government in. Like that's the thing that they've said that they don't do. There was a court case where Apple either couldn't break their own encryption or wouldn't break their own encryption. I'm not sure which one it was. Uh, and I was just talking with my friend about why Apple intelligence is so bad, and it might be because they don't know how to do it. They can't actually do it. Yeah. They can't actually implement LLMs in a way that allows them to control the phone. Because that's necessary, right? In order for AI to be not on the device, as you were saying, I think I agree with that. But uh, edge compute on your phone with an agent running everything. Is that the future? I would be surprised if that was the reason why Apple intelligence sucks. I think it's just like Apple is not really a live player anymore. Uh, since, since, since the Steve Jobs like, I think, uh, uh, they've never been particularly good at software. I mean, I switched from Pixel to iPhone earlier this year. Just to try it out. But like, the Pixel had a much better AI story even a year ago, even two years ago. Uh, things just like, yeah, I think, I think this is one of the things Google will probably do quite well because they think natively in terms of software. Like AI, AI is, is in their DNA. And when I say AI, I get, mean kind of a better lesson. I think like, often AI, often AI is not a helpful term to think in, because it's like a marketing term. You should think like, big pool of compute and data. That, like, there's a lot, like so Google search was like the original big pool of compute and data. And that's why Google adopted AI so early, is they had all the data, and they had to, they had to buy all this incredible compute. And they, you know, learned to hyperscale before anyone else. Because they have to service all this, the entirety of the internet, the biggest, essentially publicly available data set of the time. Um, and Apple just doesn't have that in their DNA. They're a hardware company. Yes. And that's, I've been going back and forth with my dad on it, and he says, uh, he loves Apple. He's part of the, the original core group of people who saw them transform from hardware to software. And so he loves that it's integrated, all in one. And that's why I bought the iPhone. I was like, okay, maybe he's right. But he wasn't right on that specific one, uh, on, on the Apple intelligence. It could be another year or two until they get, or much longer. Yeah. Google, I just also switched from the Pixel. And Google, this is the problem with the hype, is that the hype goes everywhere, and it's really hard to see it. Like six months ago, everybody was saying Google's not going to do anything. They're just lagging. And now, all of a sudden, they come up with a better video model than, than OpenAI, and how do you think it's just going to end up with the big tech companies, the big fangs, are owning the AI? Or do you think that it's going to fracture? Or do you think it's going to centralize to new players? I was talking to a friend today, whose whole stick is everything will happen. Things will be weirdly centralized, and also there'll be some like plucky 10-person startup that makes a trillion dollars in like a, in an unexpected corner of the AI space. And it's, the role that you're gearing up for is essentially how to help communities, uh, leverage this technology, right? Yeah, that's right. I think, again, this is a consequence of the bitter, the bitter lesson of scaling, scaling laws is like, getting compute and data pools into the hands of people. Exactly. And so like, by default, if you, I mean, if you really stare the bitter lesson, the scaling, scaling laws in the face, you see a story of incredible centralization. You're like, in the future, there will be a giant, like globe-spanning pool of data and compute. You know, we'll blanket the continents in data centers, and we'll suck in all the video, all the data. Most people on Earth will be in a data, will be like at a video station being recorded answering questions, whatever. And all this is being fed to this like central God AI thing. Um, and that's, like some version of that will happen. Uh, that's not like, it's not total. It's not the, it's, it's, there's, there will be an opt-out, hopefully. Yeah, well, and I think like, yes, one way is just like opt out of the whole system and like live in a physical, live in, live in the physical world. I think some small percentage of people will do that. Yeah, the Amish will do that. Hopefully we'll have like secure enough property rights and we won't have like weird social disruption that will cause that. Because if you think about it, like the story of, uh, revolutions, like the French Revolution or the Russian Revolution is a story of like the economically productive cities conquering the countryside, conquering, colonizing, and destroying the countryside. Um, so it's not, you know, like if there is a center that is incredibly powerful, um, with all this, uh, AI augmented, with all this compute, with all this data going in, like will you survive in your little corner of the world? Like how will you? In terms of the game theory, like, uh, violence Exactly, exactly. Like they will take what they want from you. No, it's possible they don't need you that much, right? Like they might, don't have robot armies so they don't have to conscript you. Um, they might just like tax your land, and you know, you'll, you'll, just like that. Well, well, I mean, land will definitely be valuable still. But it also seems like the value of land within the world that you just painted is not very valuable. What is valuable? It is just the compute and the, and the data, and the data. Um, I think land, I think it's kind of an averages over story where the value of land gets polarized. There are some kinds of land that are basically going to become totally, that are going to become totally useless. And there's types of land like, you know, uh, seaside property in San Francisco that will become The cities themselves will become So the land itself is going to change within the context of everything. It's going to still be valuable. With the depopulation thing, which definitely seems like it's happening, uh, like with that, I feel like city centers are actually going to get more valuable, right? Because it's going to be less people, more, you'll want to be around people. Going back to that earlier thing we said about social intelligence, and it all being social, is that I lived in the countryside for five years, and it was isolating. Very, very isolating. Uh, and I think as depopulation continues, that will, and it will probably be a huge, going back to the Amish point,

There'll be people who go out into the countryside and live their own lives, just trying to be, doesn't want to deal with it. Doesn't want to deal with anything that we just discussed, basically. Yeah. And then, as you mentioned in relation to the city, the city becomes pure, pure intelligence, pure data, Yeah. Yeah, yeah. unless it's a city that decides to adopt different regulations that bring other people and have the right sort of context on what AI does. Well, not the right, the right for them, cuz it's going to be a whole bunch of different tribes, basically. Right. Right. Yeah. I'm annoyed with how right Robin Hanson was in his book, Age of Em, Yeah. which I remember reading a few years ago, and it felt like kind of crazy. But I'm like, actually, if you look at the world, I mean, basically he describes like, he describes a world where AI doesn't happen. Instead, we have human emulations. Yeah. Yeah. Uh, basically uploaded copies of human brains running on hardware. Um, uh, so it's like, we don't, yeah, and, and you could say language models are actually pretty similar to this, surprisingly similar to this. They're like emulated humans. They, they speak like humans because they're trained on human text. Yeah, yeah. Yeah. But he describes like the physics of future cities, and he's like, yeah, probably ems will be concentrated in a couple or like a small handful of cities. And how will these cities be laid out? Well, because the constraint on them is information bandwidth, they'll be mile by mile by mile cubes of, of like em's basically giant data centers, because that optimizes the number of, number of, the amount of communication that can happen between different emulated humans. Uh-huh. Whoa. Okay. And I'm like, that does feel directionally what we're moving towards. And, and maybe like humans will still live in the countryside, outside of this, outside of these cities if we don't have major disruptions. You know, you'll own a 0.01% of stock in like M Enterprises, M Nvidias, and that will be enough for you to live like a king in the countryside. Yeah. Yeah. Yeah, corporations. Yeah. Uh, and yeah, cuz assuming property rights are secure, that might be fine. But in some, in some significant sense, like history will have passed us by. Like, what matters in the world is what happens inside that giant data center. Yeah. Cuz that's what they talk about the singularity. Exactly. That's the singularity, right there. Is that once you're, once you're out, you're never back in. You can't, you can't, you can't join that compute. Yeah, yeah. Yes. Your brain couldn't handle it. Yeah, yeah, yeah. Yeah, yeah. Yeah. Um, and I wanted to Yeah, it's very like you're the elf. You're, you're the elf. Like uh, the, the best frame I've had for, I've seen for relating to machine intelligence is like we are Tolkien's elves, and the machines are men. Wow. And it's like, yeah, like our time is drawing to an end. Uh, we were, you know, we had the Earth once upon a time. And now there's like this different, this different, these different kinds of entities that are like us in some ways, worse than others, better in other, better, better than others. And there's a kind of, I, I feel like this is a really good frame because it captures the grief of like the passage of something beautiful. Like, things will be lost. Yeah. Yeah. Yeah. Yeah, yeah, it's different. Yeah. Yeah. And at the same time, there's like a, okay, but like, this still is part of the plan. Like, this is just, this always had to happen. Yeah. Uh, like there's a way of letting go gracefully and like helping impart what we think is beautiful to our successors, which are the machines. Well, no, or the hybrids. Yeah. It's a matter of Or the Or the hybrids, or whatever. Does the human exist in this world? Well, no, it all depends on what you think of the human. Like, yeah, this is the craziest thing about the enlightenment stuff is that that was humanism, right? That was, that was in, in some ways, it feels like that's being lost in a lot of different things that people talk about in terms of technology. Yeah. Yeah. That humanistic element of what it means to be human, but again, it could just be cope or delusion about what the nature of the human being is. Yeah. There's a way, I think, of holding. I'm still, I'm still working this out. I think, in some ways, this will be like the religion of the future, or something. Is like, some, like religions provide, one of the things religions do is provide narratives that make sense of people's lives. And we don't, I think, have a good narrative to make sense of what's happening to us right now. But I think the narrative has to Yeah. Yeah. Yeah. Yeah. Yeah. No, we do not. be something like, yeah, we cherish what is human, but we hold it lightly somehow. We're like, we're accepting the fact that, you know, humans, humans are great, but humans are not the best arrangement. Human brains are not the best possible arrangement of compute. Um, and human, like, hands and opposable thumbs are not like the optimal thing that all of the universe should be designed around. Yeah. Yeah. We're not the center of the universe. Um, yeah, so there's a kind of like holding it lightly, taking the beautiful, generalizing it, abstracting away from it. Um, yeah.

Now, and yeah, the the thing about letting go, that gets me interested because it's like the most important thing is we tune to reality, right?

Well, now, do you agree? Do you what do you like? And can you can you can you describe it? Yeah, a distortion of reality. So, uh there's truth and then there's narratives about the truth. Yes. And the truth is usually better to focus on. Yeah. But the narratives are not optional. The narratives will happen. Yeah. So we have narrated narratives about the truth. And it feels like we're being asked to give up a lot of those narratives Yeah. about the truth. 

But not the whole thing. Yeah. Uh, I like that I like that way of putting it. I mean, I've been reading a lot of Tolkien, okay, uh, recently, and his letters uh, in particular, which were really good. And

he I think he his frame is like there is um mythmaking or fairy stories as he calls them is like a way to access a kind of truth that isn't accessible to scientific discourse. Yeah yeah. that one percent. there are some things that you can just say that are true. Uh Literally true, false, metaphorically true. true. Literally true, false, metaphorically true. Something something like that. Exactly. Literally false, metaphorically true. Or I want to say it's just like given the kinds of information processing systems that we humans are uh there are like contingent there's like abstract truths that all beings everywhere on all possible worlds would recognize like 2 + 2 = 4. Yep yep yep yeah yeah yeah. And then there's like contingent truths or like truths that kind of So Tolkien in particular talks about and this is very relevant, the myth of the fall. Uh right, the fall from grace, the fall from paradise. Yeah. And he says like every fairy story, every myth is it has to be about that in some to some extent. Wow. Because there's just something about the way humans think Yeah. that like require that like somehow forces us or requires this. This is a truth about human information processing systems. This may not be true of all possible systems. Got it. Um and so yeah, I think there's a lot of work for myth makers, yeah right, to like find what is what is now metaphorically, spiritually non non-like non-scientifically, materially true about the current state we find ourselves in and to tell those stories. It's going to be returned to Joseph Smith and Mormonism. Joseph Smith was the best at that. He was very, very good at it. I mean so was so was um uh Islam, the founder of Islam, Mohammed. Uh uh Jesus also was very good but harder to understand the historical roots of that one, but uh but Joseph Smith was wild. He was crazy. He was able to build these myths that built a new church Yeah. that allowed people to find something that if you look at Mormons, for the most part, Mormons are

according to the Western ideal pretty good off.  Like they're just really good sales people. They're really nice. I know a lot of my best friends are former Mormons, uh, and, uh, and so, but yeah, there's something there about and, and but pure fantasy, but pure fantasy built in this way that's really beautiful though as well.  Yeah. Um, But this is the hardest part and this is I just came up with a quip, I think, uh, which is that in order to prepare for the future, people should be reading Tolkien and reading his thoughts and everything like that, because there's like Kafka. It was reading Kafka, which last few years felt more like reading Kafka.  But I think we're going to have a divergence here where Tolkien will become more important due to the magical nature of a lot of the things that are happening, like the feeling that we're not in the reality that the scientism told us we would be in. Yeah.  I think that's I think that's right. And I think there's many ways of interpreting The Silmarillion and The Lord of the Rings, the whole, the whole mythology as like, this is about the transition to machines.  He even explicitly even hanging out with all the guys, the British. He's hanging out with all of them. He was reading Samuel Butler, the first person to describe, uh, like machine super intelligence improvement. He explicitly cites that in his letters. He's like, "Yeah, there is, uh," like Butler was right. Basically in the in World War II, he's like, "Butler was right, like the machines have taken over." And, uh, Samuel Butler, exactly in Erewhon and I think a pamphlet that he wrote before. Uh-huh. Uh, but yeah, first, first person to describe machine self-improving, um, machine intelligence. He was like, "Yeah, Butler was right. The machines are sovereign now." Whichever country, whichever group of people best serves the machines' interests gets gets, um, that power. That was already clear. That was already clear in World War lead up to World War II.  That was already Yeah. That was probably already clear in World War I. And in many, many ways, like his war trauma from World War I is probably a lot a lot of what drove his, uh, his mythologizing after.  Yeah. Yeah. Uh, I just found out about a, uh, Italian futurist, uh, called Marinetti.  I haven't heard of him.  Marinetti. Uh, he ended up in the fascists, with the fascists. Uh, and, and I learn I learned something about fascism from the story, and it has to relate to the machine stuff as well. Like and I'm talking about historical fascism. Yeah. Uh, historical fascism, they would actually go out and fight each other, uh, based on their ideas in order for that like gnostic, pagan type of thing of like, of, of like, you are only as good as your ideas.  If your ideas are wrong, then you'll, you'll be weak or you'll die. Yeah, yeah, yeah, yeah, yeah. Uh, and, uh, and so it's very interesting. Um, okay, so we've talked a lot about a lot of different things. I like this Butler thing, the future of machine intelligence. Um, well, actually no, let's talk about are you following anything going on with biotech, uh, anything particularly in the relationship between AI and biotech in terms of drug discovery, um, modeling, all these different things? It feels like it's really a fairly very different from LLMs. Like it feels like it's totally different, but it's going to happen. Yeah. And if you have been following, like what are you I haven't Yeah, I haven't, I haven't been following very closely. I'm probably not the right person to speak about that. Yeah, okay. Yeah. Uh, because there's biology is going to change biology in some way. It's going to change chemistry. It's going to change material science. So far, I think it'll be in this sort of way where basically, um, it's a tutor. You were saying it earlier about

Francis Bacon, uh, Newton, Yeah. Descartes, all these just polymaths who founded essential fields of science. Yeah. Yeah. I think that LLMs will bring that back. Uh, but in the sense that we've been discussing, it's like upon merging with the machine Yeah. in terms of computation. The main question I have is whether the whether this voice form of communication Yeah. is not sufficient. Hmm. Does do we need the direct brain control interface? Right. Do we need that connection? Like, is that necessary? Yeah, that's a great question. I think I'm um, I'm sort of betting currently on it not being a combination of it not being essential and it not happening fast enough. Yes. Uh, so I think like, as always, you have to think of like how far ahead, right? Like, in 100 years, will we have brain computer crazy brain computer interfaces? Probably. But in 100 years, like cloud cloud 500 will just like do all my work for me, and I'll just be like, you know, maybe occasionally consulted for matters of like taste.  Yeah. Yeah. Yeah. Cloud Cloud In that world In that world, why would you do that? Exactly, exactly. And so, Yeah, yeah, yeah. um, I think like I I more try to think about the next, say, three, five, 10 years. Yeah. And over that timescale, I really don't think we'll come up with a significantly better So I mean, yeah, just going going to like almost like raw biology here. Yeah. What is the highest bandwidth output interface humans have? It's voice. Yeah. Uh, it can speak at about 40 bits per second independent of language. So it seems to be a constraint on like literally like the human language linguistic processing center. Yeah. No. The way we think. The way we think or speak, or symbolic processing or something like that. Yeah. Okay, yeah, yeah, yeah, 'cause it's not intuition. That's right. That's also about the speed with which people read, maximum speed with which people read. So it really seems like that's a hard, like there's a hard limit. Yeah. Um, so that's language symbolic processing. Now, um, there's also like the motor cortex, which is kind of a or mostly separate part of the brain. And so, like, the dumb version of this is like, yeah, the output interface of a few of the next 10 years is still going to be voice plus cursor pointer. Um, but maybe people will come up with like something that's more gesture-controlled, so I can like just speak while just gesticulating. A hard limit, yeah. Yeah. Uh-huh. Yeah. Yeah. Uh-huh. Yeah. Yeah, okay. That seems soon, right? Like, is that Have you seen any demos of this? That seems it's, but it's it's one of those things. It seemed soon for like 10 years. And there might just there might be something about like voice is good enough to say most things, except for, uh, fine motor control, right? It's just like really hard to think about how you would replace a mouse by controlling it with your voice because that's just like language is a high throughput interface, but low-precision interface. You can't like say, "Oh, get me to like pixel 350 out of 800." Yeah. Yeah. Fine motor Um, or it's just that's not natural the natural way people think. Um, particularly for the computer part of the interface. Yeah. That's right. Because the computer's unlimited in its ability to crunch data. It's us that's the problem that can't crunch data. Yeah. Yeah. That's right. That's right. So the dumb world I'm looking at in like 10 years is still, yeah, you're still with your MacBook or your phone. You're still looking at a screen, which is probably just a rectangle. None of this projector, uh, projector VR nonsense. Um, and you're still using like a finger or a hand to point Yeah, yeah, yeah. Right. On the screen. and that's like and point on the screen. And that's still the central interface. I think people will come up with all sorts of crazy interfaces. Yeah. Um, but most of the bandwidth of most of the human-computer communication bandwidth will still go through, uh, go through, kind of, yeah, pointing, pointing and voice. Yeah. Yeah, yeah. Yeah. Being specific with the motor cortex. That's right. Uh, what do you think about new ways of communicating with the chatbots not in terms of linguistics and all This is just like a random thought, but there's like Yeah. beep

I keep on going back with the same prompts. Yeah. And that feels like, if I'm doing the same thing over and over again, Yeah. it should be automated. Right. But I still can't. I mean, maybe it's just the API. Maybe I just need to figure out how to use the API to do those things in a fluid way. Or maybe somebody's going to build a product to do that, basically. Yeah. Yeah. Um, I think a lot of this is, like, a lot of this is bottlenecked actually by social interfaces, weirdly, Oh. to language models. Like, so I'm at Midjourney now. One of the things that I think is fascinating about Midjourney is the way the community grew by sharing prompts. Like, every image, every image generation is done, almost every image generation is done in public, on a Discord server, or was on a Discord server until we had a website. Um, and so people would just see, would just scroll through Discord, see random crazy images that other people were doing, and then remix their prompts. Yeah. And whoever builds that language, that, that interface for language models will probably make a trillion dollars. Because like, It's got to be social. It's got to be social. Because culture, how, what is, what does humanity, What is humanity's superpower as a species? It's cultural intelligence. It's learning from other people, it's remixing. And so everyone chatting to their own language chatbot agent, and no one can see what anyone else is, is, is typing, or, and can't learn from each other's mistakes. Yes. This is ridiculous. Yeah. Um, and it can't, it will, it definitely won't persist this way. And that reminds me of a question I had last night, which is about APIs. Where do you think the LLMs, with their default openness versus closedness, uh, well, now the data piece that we were just talking about, like, the incentive now is to share. The incentive is to go out, share what you're learning. Not only so that you can pick it up. Yeah. Also for other people, and then also for the LLM. Yeah. And this fits into Grok's strategy, 'cause that's what Grok wants as well, is to Right. So you're talking about the incentives operating on the AI lab providers, or on people? On the users. On the users, yeah. But, and how that interacts with the one you just mentioned. Right. How do all those, does it make the API, uh, uh, does it make the API more open or more closed in general? Or a large combination of everything? Hmm.

Um, in terms of the incentive for the businesses. Right. Yeah, let's see. Huh. I'm not sure. I think this is kind of the tension at the heart of what's building these big tech empires. It's like on one hand, you gain by becoming a platform that everyone else uses. At the same time, you really want to, like, lock down the user and give them as little choice as possible, so that they can't escape your platform so that you get all the eyeballs and clicks.

Yeah. Yeah. Yeah. Yeah. Yeah.

And there's a there's another argument there for doing that, which is the, um, ease of use as well.

Sure. Yeah. Yeah, I'm inclined to I'm inclined to say that post-Steve Jobs, I don't believe. I believe that Steve Jobs was genuinely doing ease of use. I basically don't believe anyone is doing that now. I believe that I believe that people are just trying to trap you in the system. Yeah. And so, I'm much more supportive these days of GDPR-like regulations, um, for like, specifically for data portability. So like, yeah, actually

Yeah. Yeah, that's a lot more.

Oh, interesting. Ah.

What's data portability? What is data portability?

Oh, data portability, like, um, I should just have an API that I can call to get all my user data from Google, all my maps, searches, all my YouTube history. That way, you can build a startup that, like, one-click authenticates with Google and brings in my like, YouTube history, and then gives me a different YouTube feed that's like, more aligned with my interests, more aligned with what I want to do.

Okay, okay, okay, okay, okay. Yeah, yeah, yeah, yeah. Okay. Yeah.

So, GDPR got that right?

Uh, GDPR GDPR did like, a hundred different things and this is the one thing they got right, and they didn't even do it that well. I hear that the I hear that they're trying to they've learned from that mistake and they're doing it better now. We'll see. I'm skeptical.

Yeah. They did a great job.

Yeah. Yeah, okay. We'll see.

This is the hard part. And actually, this is the perfect time to talk about what we're going to talk about is the meme of Javier Milei, uh, uh, and and regulation, uh, because

Right.

Ah, fuera, a fuera, yeah, a fuera. All of it. Uh, is just running through the government in a populist way, which means that the population of Argentina, which makes sense, has now, um, is so angry at the establishment for corrupt corrupting the country. Like, all that's real.

Yeah. Yeah.

What I start to worry about is the narratives that we give it and everything like that. And I am actually supportive of Milei. I do think that it is honest of integrity. But there's also just like, a whole bunch of traps headed down the way because of everything we've talked about.

Yeah.

Yep.

And regulation, he's not getting rid of all the regulation immediately.

He doesn't have the power to, right?

He doesn't have the power. He he does have a lot of power. He's gaining a lot more power. And this is one of the interesting things about, um, the philosophies that are being talked about in Buenos Aires that are also being talked about in San Francisco, in terms of, uh, Curtis Yarvin and Curtis Yarvin talks about, uh, neo-feudalism.

Yeah.

Right.

And wants the monarchy. I haven't I haven't actually read his works, so I shouldn't I shouldn't. Uh, but I've done a lot of interviews with people who have read it.

Yeah, I got one friend who keeps on telling me to read it. But, basically, democracy. You were at this conference about democracy. There are people who want to bring back monarchy.

Yeah. Yeah.

They may be might be right, I don't know. I, like, like, and we're about to find out because there's going to be a whole bunch of different things. What I'm trying to say with this is that Javier Milei does have a very good chance of being a monarch-like figure.

Right.

Right. But this goes back to the same George Washington stuff. George Washington also had that, and in the myth he says, no.

Yeah.

Uh, the myth versus what actually happened.

Yeah.

Uh, what do you think from the outside, and now that you're here, what do you think about the meme power of Javier Milei?

Yeah. Um, so I actually, I don't have a good understanding. I'd be curious, from your perspective, what is, like, 'cause I think I I I understand why Javier Milei attracts me. I'm like, a, kind of, techno-libertarian futurist. He talks a lot about how he I also have a lot of anarchist inclinations, maybe coming from my Russian roots, um, where like I love Kropotkin, I love anarchism, the idea of like, voluntary cooperation. Um, and so when he talks about, you know, the state is fundamentally an organ of coercion, and we should like, we should we should try as much as possible to minimize coercion, to minimize violence. Like, violence is evil. I think the way he framed it on a podcast I listened to with him is like an unconditional respect for the life projects of other people. Right? And just like, yeah, just let people do the things that they want to do

Yeah. Yeah. Yeah. Yeah. Very interesting. Oh, interesting. Uh-huh. Yeah.

Yeah. Yeah. Yeah. Yeah. Yeah.

by themselves and with their communities, and do not use coercive violence.

Yeah. Yeah. And he's shown that he's not done that, so he's shown that that was real. Uh, because there's a lot of protesters in Buenos Aires who are protesting a lot of different stuff, and they do receive money from Cuba and Venezuela.

Yeah. Yeah. Right. Yeah. Yeah.

Right.

Uh, and when they planned to do those things against him, he could have used the force of the state.

Yeah. Yeah.

What he did instead was he said,

You can't you can you can uh you can protest on the sidewalk. Yeah. As soon as you go into the street, you're getting fined, and we're we're going to arrest you and give you a fine. Right. And it worked. Right. Like it was like a like an older father type figure basically saying, no more of the no more of the games. Right. Like, do this thing. You can still be yourself, you can still express yourself, yeah. Yeah. Yeah, that sounds right. I guess do you have a sense of, cuz I I don't imagine the median Argentinian Argentinian person who voted for Javier Milei has this like techno-utopian, libertarian, anarchist bias at all. Yeah. No. No, no, no. A little bit, there is a in in Buenos Aires there is. A lot of people made a lot of money on crypto here, so there are a lot of people who have who have escaped Argentina's chaos through crypto. So, I don't want to discount it completely. Yeah. And there's a lot of young people, uh a lot of young people who are worked for San Francisco startups, so they're familiar with everything that's going on in San Francisco. Yeah. Yeah. Uh and there's also the demographic thing, which is really interesting, and it's the only one of the main reasons that Javier Milei was elected was that there is there is a demographic crisis here. It started 20 years after the United States, 20 years after Brazil. Uh so, it started uh to the point where there's a huge young population of uh zoomers, Yeah. who have been bred on the internet, uh and I think there it's representative of what's going to happen in the United States once the zoomers become more populist, more majority. Right. So, there is that. Or once the boomers really retire. But really, it's economic. The reason why I believe he was uh voted in was economic populism. Right. Uh just total mismanagement of the economy for Right. to the point where everybody was pretty apolitical. Okay. Cuz Milei's not the first time that this has been tried. Right. Menem in the 90s, right? Yeah, Menem in the 90s, and then Macri in 2010s. Yeah. The Kirchner's are the big um

the big sort of like they were the after Bill Clinton late-stage neoliberalism. Right. The type of neoliberal thing that was just defeated at the ballot box in the United States. They had that here earlier. Wait, you're telling me most people, but like the average person who voted for Milei voted for him because they were like disgusted with the opposition, not because they actually liked Milei? No, I wouldn't say that. I would say that he became the symbol Uh-huh. that attracted them Hmm. to what I think is an integerous version of actually identifying the problem Yeah. and he this is the thing we talked about earlier too is just that in his speeches, he's really honest. He's really honest about the particular micro economic details. Yeah. Uh I don't know if that came in the Lex Friedman podcast, okay, yeah. Yeah, yeah, yeah. So he's just like really upfront and saying things truthfully with no pretention about Yeah. how the message is received. And so I think that's what attracted them. But I'm not sure, I've only been here for a year. Now that I'm back here, I'm going to start doing a lot more interviews in Spanish with all the party from Libertad Avanza. Uh La Libertad Avanza is his party. There's only six senators who have been voted in at the national level because it's a completely new party. Nobody expected Milei to win. Right. And so six senators, and then there's a few seats in the house as well. So starting 2025 is the midterms. And that's where the momentum of what he's doing gets proven, which right now seems like it would not be a bet I would bet against. Like momentum is just

really really in their favor. Um, yeah, a question I have for you actually uh that comes that came from the Lex Friedman interview is I felt like

Yeah, Milei was talking a lot about the state and the curse of power of the state and how we want to remove that and how like the state will no longer be there for you for a lot of people, right? In a way that it has been. Yeah. And I thought, it feel- it felt natural to me to like complete that message with like a call to a call to volunteerism? A call to like, "The state will no longer be there for you, so maybe like check in on your neighbor. Like check that they're doing well and like maybe help them out if they're not." Because I think if it happen- and it didn't happen. And so, and and I feel like this like Yeah. Yeah. Yeah. Interesting. Yeah. Yeah, yeah. Yeah. Interesting. uh, libertarianism plus indiv- plus individualism is a self-undermining ideology. Because like, people fundamentally want to help and be helped. And if you don't fulfill that with voluntary means, this is the emptiness of like the Ayn Rand ideology, right? Like it doesn't have room for love. Uh, if you if you don't make space for voluntary cooperation, you will get involuntary cooperation via the state via the oper- the apparatus of power. Yeah. Yeah. Yeah. Yeah, yeah. Yeah. Interesting. I'm curious how how you respond to that. Yeah, yeah, yeah. So, uh, Milei represents New Thought. New Thought is an American, from Quigley, uh, philosopher, uh from United States, that talked about manifestation. Making you think it, it happens. No question. Also Ayn Rand. So, very, very much individualism. Right. Argentina is not i- could be said to be libertarian in the same way that the United States kind of had these libertarians involved with this whole statecraft in 1700s, they had that here. But is much more collectivist. So there's one aspect of

being having to separate themselves from that collectivist energy and everything like that. Because Argentinians already do that. A lot a lot of Argentinians already have a family support network. That's one of the things I love about being in Argentina is that

Everybody, all the family is still involved. So if you need somebody to help, the social network is still pretty strong here. Yeah. Whereas in the United States it had social network, the civil, like that thing that you just mentioned, the United States used to be a paragon in the 1960s of like you help out your neighbor, you have these civic organizations, you donate your time like. I was 1830s was the Golden Age of that but sure. Oh interesting, 1830s? Like Tocqueville in Democracy, the way Tocqueville describes like any problem that comes up, Americans just form an association for it. There's associations everywhere, associations for everything. Everyone's a member of a hundred different associations. Yeah. That also happens here. Yeah? That also happens here. Everybody has a country club and a golf club and they all go to the same thing and so they all do that. But I think you're right. You're not bowling alone in Argentina, huh? No.

If they want to, they go to the States. And they build, they go to Silicon Valley, and there's a lot of them there. Right. Right. Uh but that might change because the individual, but I think you're accurately representing the problem which is that what if it's all just a memetic oh, like, that's cool. Uh, attracts a bunch of people. But we don't get the middle class back. Well, it's not, yeah, it's not, it's not um There's like sustainable memeplexes and there's unsustainable ones. I feel like libertarianism is just self-undermining because it doesn't, it doesn't quite cohere with human nature. I think like opposition to the state has to be like combined with a uh, love for one's neighbor or something, uh, in order to be coherent. Yeah. Okay. This is, this is why I like, uh, Jacques Ellul, who's a Christian anarchist philosopher from the 1960s. He's, yeah. Oh, I need to read this guy, Jacques Ellul. Well, he's also the guy who, uh, uh, uh, Ted K, uh, uh, took the ideas and ran with them in a direction that I don't think, uh, Jacques Ellul would, uh, appreciate. Yeah, it's never the Christians that are like bombing, uh, they're bombing government buildings or something. Yeah. But that's what, that's Nietzsche had a problem with them because they didn't do that. Right. Uh, which is also another thread. We'll just do another five minutes or so. Sounds good. Uh, yeah, give to Caesar what is Caesar's. Uh, I support paying your taxes and not bombing government buildings. Yes, yeah, yeah. Yeah, man, that's another thread that we could go down. I'm not sure I want to go down, uh, of, uh, what just happened in US. We'll leave that for another time, but, uh, uh,

That's what brings to mind of of why it's interesting for me to be here during this time. What do you think's going on in the US? What do you think is is where where is the US headed to now? Oh man. That's such a that's such a big question. Thanks for thanks for thanks for making it easy for me, dude. Um, yeah, maybe it's good to articulate like what my roots are. I'm like a Russian Jew, who like, grew up in Canada, uh, and moved to the US quite recently. Um, yeah. The US, huh, seems to me like a very sick society in a lot of ways. Yeah. I mean, you can see it just on the streets of San Francisco or the streets of New York. Um, there's a lot of, uh, like, there's a sense of the like the the social contract is really just not there. Yeah. Um, It's broken down. It's broken down. Uh, people don't feel like their neighbors are their responsibility. Yeah. And that, I don't think that can last long term, like, there's just not a sustainable way for people to live. Um, uh, the, like, the amount of dissociation you have to have in order to go through a day in San Francisco, Yeah. uh, going from, like, incredible wealth to incredible poverty and addiction, Yeah. um, is not is just like, not sustainable on the human soul long term. Uh, at the same time, I mean, like, it's an incredibly dynamic place, maybe the only dynamic place in the world. I mean, you probably disagree with that. Uh, Yeah, I mean, I'm hopeful, but I'm I'm on hope still. I'm not I'm on hopium. Uh, Yeah, not the pure hopium about the state of the world just because, uh, Right. uh, so, I love Argentina and, I mean, I'll be honest here, one of the awesome things about Argentina is that it is cheaper than the United States. Yep. It was a lot cheaper, and so, even if it it if it does get worse here, if it does revert, um, it's a it's I fucking love Buenos Aires. It's a beautiful, beautiful place. We've just been walking around the park all day. Yeah. So, uh,

Yeah, it's it's it's I'm I'm I'm always an optimist. Yeah. But I've become a much less naive optimist, I would say. Yeah. Uh, over the last four years and I'm uh I'm hopeful that Argentina and I'm I'm now hopeful that the United States is also going to do something interesting. Right. Particularly with the accelerationism stuff. Mm. Uh, because now it feels like doors are open.

But too big of a door on accelerationism, I think, is a problem. Right. I would frame it as like, yeah, accelerationism versus safetyism is kind of like the wrong binary. Like, the question is, uh they're both kind of like bloodless liberal ideologies that have no meat to them. Like, tell me what you want to accelerate. Like what do you want to see in the world? You know, I'm like a tree accelerationist. I'm a Tolkien accelerationist. I'm like a Dunbar scale village accelerationist. Am I a state accelerationist? Do I want like the state to be even more powerful and even smarter and like, uh, do I want, uh, um, yeah, as as I think that's that's kind of the, that's the sense in which I keep coming back to the bitter lesson, the scaling laws. I'm like the thing that you need to integrate is like the things that survive into the future are ones that can somehow leverage or mesh with these, like, giant pools of data and compute. And so the like, the call to arms, the call to arms for all of us is just like the things that find like figure out the things that you really care about and value and then figure out a way to make that to accelerate them. Uh, because by default, they won't, they won't make it. They won't go, and this goes into the land stuff. Nothing human makes it other than you. Interesting. Okay, so he is a humanist. Is Nick Land a humanist? Um, I would say he's, he would say I think he's a philosopher, and he's describing the world as he sees it. And then like, the question of humanism is a religion, uh, not, not, not a, it's a, it's a position about what ought to be and not what is. Oh, interesting. Um, thank you so much for coming to the show. Find out Evan Vendroff on Twitter. Evan, Evan Vendroff on Twitter. Evan Vendroff on Twitter or nothinghuman.substack.com. Great.